{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward algorithm\n",
    "\n",
    "Given the set of observation $\\textbf{X}^{(T)}=(X_1, X_2 ... X_T)$ and HMM model parameters $\\theta$ the likelihood of the observations $\\textbf{x}^{(T)}$ is given by\n",
    "\n",
    "$$ L_T = P(\\textbf{X}^{(T)} = \\textbf{x}^{(T)} | \\theta) = \\boldsymbol{\\delta} \\boldsymbol{P}(x_1) \\boldsymbol{\\Gamma} \\boldsymbol{P}(x_2) ... \\boldsymbol{\\Gamma} \\boldsymbol{P}(x_T) $$\n",
    "\n",
    "where $\\boldsymbol\\delta$ is the 1 X N the vector containing the inital probability distribution, $\\boldsymbol\\Gamma$ is the N X N matrix of transition probabilities and $\\boldsymbol P (x)$ is a N X N diagonal matrix of state-dependent densities.\n",
    "\n",
    "The likelihood can be effciently computed using dynamic programming. Defining the 1 X N probability vector\n",
    "$$\\boldsymbol \\alpha_t = \\boldsymbol{\\delta} \\boldsymbol{P}(x_1) \\boldsymbol{\\Gamma} \\boldsymbol{P}(x_2) ... \\boldsymbol{\\Gamma} \\boldsymbol{P}(x_t) $$\n",
    "\n",
    "Which can be calculated using the recursion\n",
    "$$ \\boldsymbol \\alpha_1 = \\boldsymbol \\delta \\boldsymbol P(x_1)  $$\n",
    "$$ \\boldsymbol \\alpha_t = \\boldsymbol \\alpha_{t-1} \\boldsymbol \\Gamma \\boldsymbol P(x_t) \\quad \\text{for t = 2,3...T} $$ \n",
    "$$ L_T = \\boldsymbol \\alpha_T \\boldsymbol 1' $$\n",
    "\n",
    "\n",
    "### Pseudo code for computation of the log of scaled forward probabiltities\n",
    "\n",
    "Let $\\boldsymbol{\\delta, \\Gamma, P(x)}$ be defined as above. Further, let $\\boldsymbol\\phi$ and $w$ be vectors of length N (where N is the number of hidden states), $llk$ is a scalar to store log likelihood.\n",
    "\n",
    "Init:\n",
    "$$\\boldsymbol \\alpha_0 = \\boldsymbol \\delta \\boldsymbol P(x_0)$$\n",
    "$$ w_0 = \\boldsymbol \\alpha_0 \\boldsymbol 1 $$\n",
    "$$ llk = log(w_0) $$\n",
    "$$ \\boldsymbol \\phi_0 = llk + log(\\frac{\\boldsymbol \\alpha_0}{w_0}) $$\n",
    "\n",
    "\n",
    "For t = 2,3..,T:\n",
    "$$\\boldsymbol \\alpha_t = \\frac{\\boldsymbol \\alpha_{t-1}}{w_{t-1}} \\boldsymbol \\Gamma \\boldsymbol P(x_t)$$\n",
    "$$ w_t = \\boldsymbol \\alpha_t \\boldsymbol 1 $$\n",
    "$$ llk = log(w_t) $$\n",
    "$$ \\boldsymbol \\phi_t = llk + log(\\frac{\\boldsymbol \\alpha_t}{w_t}) $$\n",
    "\n",
    "\n",
    "Return $llk$ and $\\boldsymbol \\phi$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JUMP model theta derivatives\n",
    "\n",
    "The L2 norm is defined as\n",
    "$$ ||\\textbf{x}||_2^2 = (\\sqrt{\\sum_i x_i^2})^2 = \\sum_i x_i^2 = \\textbf{x'x} $$\n",
    "\n",
    "where $\\textbf{x}$ is a vector.\n",
    "Using that, then the loss function in a jump model is\n",
    "\n",
    "$$ l(z_t, \\theta_{st}) = ||z_t-\\theta_{st}||_2^2 = (z_t-\\theta_{st})'(z_t-\\theta_{st}) $$\n",
    "\n",
    "And the partial derivative of $\\sum_{t=1}^{T} ((z_t-\\theta_{st})'(z_t-\\theta_{st})$\n",
    "\n",
    "$$ \\frac{\\delta \\sum_{t=1}^{T} ((z_t-\\theta_{st})'(z_t-\\theta_{st}) }{\\theta_j} $$\n",
    "$$ = \\frac {\\sum_{t=1}^T (z_t'z_t - 2z_t'\\theta_{st}+ \\theta_{st}'\\theta_{st} )}{\\theta_j} $$\n",
    "$$ = \\sum_{t:s_t=j} ( 2\\theta_{st}' - 2z_t' ) $$\n",
    "\n",
    "Thus the partial derivative for $\\theta_j$ is the sum of all t where the state $s_t=j$ of the vector $theta_{st}$ and $z_t$\n",
    "\n",
    "Setting that equal to zero yields the solution:\n",
    "\n",
    "$$ \\theta_j = \\frac{1}{N_j} \\sum_{t:s_t=j} z_t $$\n",
    "\n",
    "where $N_j$ is the number of elements in $s_t=j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Forward algorithm scaling explained\n",
    "See p. 48 in Zucchini\n",
    "\n",
    "Let $\\alpha_t = (\\alpha_t(1)..\\alpha_t(m))$ be the forward probability vector at time t with m denoting the amount\n",
    "of states. Then the likelihood can be calculated recursively as:\n",
    "\n",
    "For $t=0$:\n",
    "\n",
    "- $\\alpha_{0} = \\delta \\cdot P(x_0)$\n",
    "- $w_0 = \\sum_{j=1}^m \\alpha_0(j) =  \\alpha_0 \\cdot \\textbf{1'} $\n",
    "- $$\\phi_0 = \\frac{\\alpha_0}{w_0}  $$\n",
    "- $$log L_0 = log(w_0)  $$\n",
    "- $$ log (\\alpha_0) = logL_0 + log(\\phi_0) $$\n",
    "\n",
    "For $t\\in 1..T$.\n",
    "- $\\alpha_t = \\phi_{t-1} \\cdot \\Gamma \\cdot P(x_t)$\n",
    "- $w_t = \\sum_{j=1}^m \\alpha_t(j) =  \\alpha_t \\cdot \\textbf{1'} $\n",
    "- $$\\phi_t = \\frac{\\alpha_t}{w_t}  $$\n",
    "- $$log L_t = L_{t-1} +  log(w_t)  $$\n",
    "- $$ log (\\alpha_t) = logL_t + log(\\phi_t) $$\n",
    "\n",
    "From this it is clear that:\n",
    "\n",
    "$logL_T = \\sum_{t=1}^T log(w_t) = \\sum_{t=1}^T log(\\alpha_t\\cdot \\textbf{1}^T) =\n",
    " \\sum_{t=1}^T log(\\phi_{t-1} \\cdot \\Gamma \\cdot P(x_t)\\cdot \\textbf{1}^T) $\n",
    "\n",
    " Thus the log likelihood follows directly from p. 48 in Zucchini.\n",
    "\n",
    " TODO $\\alpha_T$ however doesn't seem to match as:\n",
    "\n",
    "$log(\\alpha_T) = \\sum_{t=0}^T [log(w_t)] + log(\\frac{\\alpha_T}{w_T}) $\n",
    "\n",
    "Since $log(x)+log(y)=log(x*y)$ then:\n",
    "\n",
    "$log(\\alpha_T) = log(w_0*w_1*...*w_{t-1}*w_T*\\frac{\\alpha_T}{w_T}) $\n",
    "\n",
    "$log(\\alpha_T) = log(w_0*w_1*...*w_{t-1}*\\alpha_T) $\n",
    "\n",
    "$\\alpha_T = \\prod_{t=0}^T (\\alpha_t\\cdot \\textbf{1}) * \\alpha_T  $\n",
    "\n",
    "WHICH DOESn't MATCH P. 48 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Rewriting $f_{jk} = \\hat v_{jk}(t) $\n",
    "To make the code more efficient\n",
    "\n",
    "From the definition on p. 71 we have\n",
    "\n",
    "$f_{jk} = \\sum_{t=2}^T \\hat v_{jk}(t)$\n",
    "\n",
    "$ \\hat v_{jk}(t) = \\gamma_{jk}\\alpha_{t-1}(j)p_k(x_t)\\beta_t(k)/L_T $\n",
    "\n",
    "Since $\\gamma_{jk}$ doesn't depend on t we can move it outside expression in $f_{jk}$\n",
    "\n",
    "$f_{jk} = \\gamma_{jk} \\sum_{t=2}^T \\alpha_{t-1}(j)p_k(x_t)\\beta_t(k)/L_T $\n",
    "\n",
    "We can then denote $\\alpha_j$, $\\beta_k$ and $P_k(x)$ as 1 x T vectors containing all time-dependent values given the state j and k to obtain:\n",
    "$f_{jk} = \\gamma_{jk} \\sum_{jk} \\alpha_{j}P_k(x)\\beta_k/L_T $\n",
    "\n",
    "Which now only only requires looping through possible values of j and k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.3, 0.2, 1]\n",
      "[0.78208539 0.66644921 0.73654028 0.10798193]\n",
      "[0.12712927 0.12940956 0.12833562 0.13298076]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "obs = [0.1, 0.3, 0.2, 1]\n",
    "print(obs)\n",
    "print(stats.norm.pdf(obs, loc=0, scale=0.5, ))\n",
    "print(stats.norm.pdf(obs, loc=1, scale=3, ))\n",
    "\n",
    "\n",
    "#print(stats.norm.pdf(0, loc=[0,1], scale=[0.5,3], ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-88dad6320369>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m                        + ((X[:, None, :] - means) ** 2 / covars).sum(axis=-1))\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0m_log_multivariate_normal_density_diag\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-29-88dad6320369>\u001B[0m in \u001B[0;36m_log_multivariate_normal_density_diag\u001B[0;34m(X, means, covars)\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0;34m\"\"\"Compute Gaussian log-density at X for a diagonal model.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;31m# X: (ns, nf); means: (nc, nf); covars: (nc, nf) -> (ns, nc)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mn_samples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_dim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0;31m# Avoid 0 log 0 = nan in degenerate covariance case.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mcovars\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaximum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcovars\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtiny\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}