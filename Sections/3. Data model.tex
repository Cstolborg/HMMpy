\newpage
 \section{Data model}
 
 \textbf{Skriv introduktionen her om. Særligt nogle af beskrivelserne i anden paragraf er for tekniske og bør ikke gennemgås førend de er defineret nede i afsnit 3.1. Der kan godt være en mere high-level intro til HMMs, deres antagelser og brugsområder her istedet.}
 
Real-world processes generally produce directly observable output which can be characterized as signals (Rabiner, 1989). As an example, a signal could be the different letters from an alphabet or, as in the case of this thesis, prices from a financial index like the S\&P 500. These signals can be discrete or continuous and stationary or non-stationary, hence it is of fundamental interest to characterise the signals through the use of signal models. There are several possible choices of model for characterising the properties of a given signal. Typically, the selected model either stems from a class of deterministic models or statistical models (Rabiner, 1989). As such, the deterministic model generally exploit a known specific property of the signal, for instance that the signal behaves like a sine wave. However, this type of model is not appropriate in this application since financial returns do not behave in such nice properties. On the other hand, the statistical models which include Gaussian and Markov processes as well as hidden Markov processes, operate under the assumption that the signal can be characterised as a parametric random process and the parameters of the stochastic process can be estimated (Rabiner, 1989). Given these assumptions and properties, the hidden Markov model should serve as a prime data model for capturing the stochastic nature of financial returns.

The HMM was originally introduced by Baum \& Petrie (1966) and later by Baum et al. (1970) after which the model has been applied in many fields, such as biology (Durbin et al. 1998), environmental time series (MacDonald \& Zucchini 1997) as well as speech recognition (Rabiner 1989). One of the most well-known articles within the field of finance involving the use of HMMs on daily financial return series is authored by Rydén et al. (1998). The study found that a  Markovian mixture of normal variables are able to reproduce most of the stylized facts for daily return series which were introduced by Granger \& Ding (1995b). As such, the existing literature have cemented the applicability of HMMs when it comes to modelling daily financial return series and reproducing the stylized facts, hence the HMM will serve as the data model throughout this thesis.

Furthermore, as highlighted throughout section \ref{section: Data}, a traditional Gaussian distribution does not capture the distributional properties of financial return series. Another issue with applying predictive techniques to financial return series is that the models often assume stationarity, however, Hamilton (1989) found that financial returns are often characterised as non-stationary due to changing means and heteroscedasticity. Despite these findings it should be noted that even though stationarity might not be fulfilled across long time horizons, the condition is often fulfilled over temporary periods (Hamilton, 1989). As such, mixtures of Gaussian distributions provide an enhanced fit since these distributions are better at reproducing the aforementioned stylized facts both in terms of leptokurtosis and skewness. This further strengthens the argument for using HMMs to model the daily financial return series. 

The theory of HMMs in discrete time as well as the mathematics underlying their estimation procedure is outlined through section \ref{subsection: HMM} to \ref{subsection: Decoding}. In addition, the thesis will be exploring a model estimation method, in which the jump framework of Bemporad et al. (2018) is combined with the temporal features used by Zheng et al. (2019), in order to estimate HMMs. This methodology is known as the \textit{jump estimator} and will be reviewed in section \ref{subsection: Jump theory}. As such, the jump framework serves as an alternative to the well established MLE approach. 


\subsection{Hidden Markov Models}
\label{subsection: HMM}
\textbf{Still missing description of stationary distribution and model initialization}

The fundamental aspect of an HMM is that the underlying distribution that generates an observation is dependent on the state generated by an unobserved Markov chain. In addition, the transition probabilities, which determine the probability of which a state change occurs, are assumed to be constant, thereby implying that the sojourn times, i.e. the amount of time spend in each state, are geometrically distributed.

Hidden Markov Models, are probabilistic models whose primary function is to predict sequences of unobserved (hidden) states from a set of observed variables. The observed variables could be a log return series of a financial asset or index like the S\&P 500. The model’s inference of hidden states is based on an underlying Markov process. Therefore, as opposed to other traditional models which assume independence among observations, Markov models assumes that the sequence of observations and the associated classifications are dependent. Furthermore, the Markov property states that the classification of a state is only dependent on the former classification i.e. the previous instance. 

Let $\K=\{ 1,\ldots, K \}$ denote the state space with $K$ states, and let $\S=(s_1,s_2,\ldots,s_T)$ be a sequence of latent (unobservable) discrete random variables where $s_t\in\K: t\in \mathbb{N}$ is the state active at time $t$. Then, $s_t$ is assumed to follow a first order Markov chain where, for all $t \in \mathbb{N}$, the future state at $t + 1$ solely depends on the current state, fulfilling the Markov property. The first order Markov property is expressed through equation \ref{eq:model_markov_property}
\begin{equation}
    P(s_t | s_{t-1},\ldots,s_1) = P(s_t | s_{t-1}),
    \quad t=2,\ldots,T
    \label{eq:model_markov_property}
\end{equation} 

As such, the Markov property provide a neat mathematical simplification, since if one were to determine the probability that the current state $s_t$ is equal to some state $i$, it would require knowledge of all the states that have come before $s_t$. Given the Markov property, this knowledge can be reduced to only knowing the previous state $s_{t-1}$. The switching behaviour of $s_t$ is governed by the conditional probabilities $Pr(s_{t+1} = j| s_t = i) = q_{ij}$, where $q_{ij}$ is the probability of switching from state $i$ to state $j$ (Bulla et al., 2011). These are referred to as transition probabilities and they are stored in a transition probability matrix denoted as $Q = \{q_{ij}\} \in [0,1]^{K \times K}$. The initial distribution of the transition probability matrix is stored under the variable $P(s_1|O)= \delta$.

Following the definition of the transition probabilities as well as the initial probability matrix of observing a particular state, it is important to define the the observable data. As such, define $o_t \in \mathbb{R}$, as a random variable of the observed data at time $t$ and let $O=(o_1,\ldots,o_t)$ be the sequence of observed data. Closely connected to the defined observable data lies the assumption that HMMs operate under output independence, as expressed in equation \ref{eq: Output independence}.
\begin{equation}
    P(o_t|O, \S) = P(o_t|s_t),
    \quad t=2,\ldots,T
    \label{eq: Output independence}
\end{equation}
As a result of the output independence, the distribution of the observable data depends only on the current state, thereby making the autocorrelation functions highly dependent on the persistence of $s_t$. Lastly, the emission probabilities are defined as

\textbf{Skriv ind som fuld matrice - dvs. lav en $2\times2$ matrice og indsæt værdierne af $b_j(o_t)$ på deres respektive pladser.}
\begin{equation}
    B_t(o_t)= \{ P(o_t|s_t=j) \} = \{ b_j(o_t) \}, \quad \forall j \in \K, t=1,\ldots,T 
\end{equation}
where $B_t(\cdot)\in \mathbb{R}^{K\times K}$ is a diagonal matrix with state dependent probabilities, i.e. the probability of observing $o_t$ at time $t$ from state $j$. Following this acknowledgment, the sequence state dependent probabilities are defined as $B=(B_1,\ldots,B_T)$. In addition, it should be noted that when the state dependent distribution is continuous, $b_j(o_t)$ represents conditional densities rather than conditional probabilities (Jurafsky Martin, 2019). Since the HMMs utilized in this thesis will be discrete the state dependent distribution will be expressed as conditional probabilities rather than conditional densities. Conclusively, an HMM is a state-space model with finite state space, in which equation \ref{eq:model_markov_property} is the state equation and equation \ref{eq: Output independence} is the observation equation. A specific observation can potentially arise from more than one state, since the conditional distributions between the states can overlap.

\textbf{Insert a summary of all defined variables in either a table or by using bullet points.}

\subsection{A 2-state Hidden Markov Model}
Having defined the variables underlying discrete HMMs, the following section will introduce a 2-state HMM. It should be clear that the example could easily be expanded to include more states, however, the direct link between a 2-state model and the different macroeconomic environments represented as either expansions or recessions makes a 2-state model intuitive and feasible. Consider the 2-state model with Gaussian conditional distributions specifications
\begin{equation}
     o_t|s_t \sim N(\mu_{s_t},\sigma^2_{s_t}) 
\end{equation}
\begin{equation}
   o_t = \mu_{s_t}  + \sigma_{s_t}\epsilon_{t}
   ,\quad \epsilon_{t} \sim N(0,1)   
\end{equation}
where,

$$
    \mu_{s_t}=
    \begin{cases}
        \mu_1, & \text{if}\ s_t = 1 \\
        \mu_2, & \text{if}\ s_t = 2
    \end{cases},
    \sigma_{s_t} =
    \begin{cases}
        \sigma_1, & \text{if}\ s_t = 1 \\
        \sigma_2, & \text{if}\ s_t = 2
    \end{cases},
    Q = 
    \begin{bmatrix}
    q_{11} & q_{12} \\
    q_{21} & q_{22}
    \end{bmatrix},
    \Theta = (Q, B, \delta)
$$
in which $\Theta$ captures the estimated model parameters defined in section \ref{subsection: HMM}. The nature of the workings of an HMM is quite intuitive. For every period $t$, the model observes a realization $o_t$ from the current conditional distribution. As such, one can think of this as drawing an observation form an underlying distribution, however, it is unknown whether $s_t = 1$ or $2$. Further, the properties underlying the transition probabilities in $Q$ are also unknown. As such, the objective of the HMM is to estimate the most likely sequence of states $\S$, as well as the most likely parameters, $Q$, $B$ \& $\delta$. Furthermore, as previously mentioned, the sojourn times are implicitly assumed to be geometrically distributed as per equation \ref{eq: sojourn time}
\begin{equation}
    P('\text{staying $t$ time steps in state $i$'}) = q^{t-1}_{ii} \cdot(1-q_{ii})
    \label{eq: sojourn time}
\end{equation}
As such, the expected duration of state \textit{i} can be depicted as 
\begin{equation}
    E[r_i] = \frac{1}{1-q_{ii}}
    \label{eq: geometric distribution memory}
\end{equation}

As evident by equation \ref{eq: sojourn time} and \ref{eq: geometric distribution memory}, the geometric distribution of the sojourn times is memoryless, implying that the time until one observes a transition out of the current state is independent of the amount of time spend in the current state. This is one of the apparent weaknesses when utilizing HMMs for modelling regime-switching behavior in economics, since macroeconomic variables are not memoryless. Lastly, it should be clear that the mathematics associated with HMMs can become quite complicated hence one of the challenging aspects associated is estimating the model parameters. This is discussed in the following section.

Before moving on to the section that introduces the mathematics, table \ref{tab:summary_hmm_variables} has been included to provide a summary of the variables underlying an HMM. As such, the table should serve as a point of reference going forward.
\begin{center}
\small\addtolength{\tabcolsep}{-5pt}  
\begin{table}[H]
    \caption[Overview of the variables in HMMs]{Overview of the variables in HMMs}
    \centering
    \begin{tabular}{l c c} 
    \hline\hline
    Variables & Domain & Summary \\
    \hline 
    \underline{Hidden Markov Variables} \\
    $O$ = ${(o_1, o_2,\ldots o_T)}$ & $O \in \mathbb{R}^T $ & Observation sequence \\
    $S$ = ${(s_1, s_2, \ldots s_T)}$ & $S \in [0, K]^T $ & State sequence\\
    $B_t = \{ b_j(o_t) \} = \{ P(o_t|s_t=j) \}$ & $B_t \in \mathbb{R}^{K\times K}, b_j(o_t)\in\mathbb{R}$  & Emission probability matrix \\
    $Q$ = $\{q_{ij}\}$ & $Q \in [0,1]^{K \times K}$ & Transition probability matrix \\
    $\delta = P(s_1|O$) & $\delta \in [0,1]^{K \times K}$ & Initial probability distribution \\
    $\pi$ = $Q 1^T$ & $\pi \in [0,1]^K$ & Stationary Markov chain \\
    $(\mu_{s_t}, \sigma_{s_t})$ & $(\mu, \sigma) \in \mathbb{R}^K$ & conditional Gaussian distribution \\
    \underline{Forward-backward algorithm} \\
    $\alpha_t(i) = P(o_1,\ldots,o_t, s_t = i | \Theta)$ & $\alpha \in \mathbb{R_+^{K \times T}}$ & Joint probability state $i$ and $o_1,\ldots,o_t$  \\
    $\beta_t(i) = P(o_{t+1},\ldots,o_T | s_t = i, \Theta)$ & $\beta \in \mathbb{R_+^K}$ & Probability of future $O$ given state $i$   \\
    \underline{Baum-Welch algorithm} \\
    $\gamma_i(t)$ = $P(s_t=i|O)$ & $\gamma_i(t) \in [0,1]^{K \times T}$ & Probability of state $i$ given entire $O$ \\
    $\xi_{ij}(t) = P(s_{t-1} = i, s_t = j |O)$ & $\xi_{ij}(t) \in [0,1]^{K \times T}$ & Probability of state $i$ followed by $j$ \\
    \underline{Viterbi algorithm} \\
    $\upsilon_t(i) =\max_{s^{(t-1)}} P(s^{(t-1)}, s_t=i, O | \Theta)$ & $\upsilon_t(i) \in [0,1]$ & Finds the most likely state at each $t$ \\ 
    \hline
    \end{tabular}
\label{tab:summary_hmm_variables}
\end{table}
\end{center}
